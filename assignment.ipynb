{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=color:red>Basic image manipulations 1<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " ...\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]\n",
      " [255 255 255 ... 255 255 255]]\n",
      "[[[ 90  14  18]\n",
      "  [ 90  14  18]\n",
      "  [ 92  12  15]\n",
      "  ...\n",
      "  [ 22   3   5]\n",
      "  [ 24   4   6]\n",
      "  [ 24   4   6]]\n",
      "\n",
      " [[ 88  12  16]\n",
      "  [ 88  12  16]\n",
      "  [ 90  10  13]\n",
      "  ...\n",
      "  [ 17   0   0]\n",
      "  [ 18   0   0]\n",
      "  [ 19   0   1]]\n",
      "\n",
      " [[ 86  10  12]\n",
      "  [ 87  11  13]\n",
      "  [ 89   9  12]\n",
      "  ...\n",
      "  [ 16   0   0]\n",
      "  [ 18   0   1]\n",
      "  [ 18   0   1]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[138  30  53]\n",
      "  [137  29  52]\n",
      "  [140  32  55]\n",
      "  ...\n",
      "  [246 173 202]\n",
      "  [248 175 204]\n",
      "  [249 176 205]]\n",
      "\n",
      " [[139  31  54]\n",
      "  [138  30  53]\n",
      "  [139  31  54]\n",
      "  ...\n",
      "  [244 169 199]\n",
      "  [246 171 201]\n",
      "  [247 172 202]]\n",
      "\n",
      " [[140  32  55]\n",
      "  [138  30  53]\n",
      "  [139  31  54]\n",
      "  ...\n",
      "  [242 167 197]\n",
      "  [243 168 198]\n",
      "  [244 169 199]]]\n",
      "(2268, 4032)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    " \n",
    "red=np.full((512,512),255,dtype='uint8')\n",
    "green=np.full((512,512),0,dtype='uint8')\n",
    "blue=np.full((512,512),0,dtype='uint8')\n",
    "# stacking three channels \n",
    "arr=np.stack((red,green,blue),axis=-1)\n",
    "# converting an image into array\n",
    "img=im.fromarray(arr)\n",
    "img.show()\n",
    "print(red)\n",
    "i=im.open(r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg')\n",
    "i.show()\n",
    "# converting an image into array\n",
    "img=np.array(i)\n",
    "print(img)\n",
    "print(i.size)\n",
    "# adding a alpha channel to make the picture blur\n",
    "opc=np.full((img.shape[0], img.shape[1]),100,dtype='uint8') \n",
    " #need to use img.shape[0]This ensures opc matches the height and width of the loaded image.\n",
    "st_arr=np.stack((img[:,:,0],img[:,:,1],img[:,:,2],opc),axis=-1)\n",
    "st_img=im.fromarray(st_arr,mode='RGBA') #When creating the new image from the array, use RGBA mode since you’re adding an alpha channel.\n",
    "st_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Grey Scale<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "i=im.open(r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg')\n",
    "# i.show()\n",
    "i = i.convert('RGB')\n",
    "red_channel, green_channel, blue_channel = i.split() #image.split() separates the Red, Green, and Blue channels into individual grayscale images.\n",
    "\n",
    "# Display each channel\n",
    "#show() opens each channel in a separate window using the default image viewer on your system.\n",
    "red_channel.show(title=\"Red Channel\")\n",
    "green_channel.show(title=\"Green Channel\")\n",
    "blue_channel.show(title=\"Blue Channel\")\n",
    "image_array = np.array(i)\n",
    "\n",
    "# Compute the average of the RGB channels\n",
    "grayscale_array = image_array.mean(axis=2).astype(np.uint8)\n",
    "\n",
    "# Convert the grayscale array back to an image\n",
    "grayscale_image = im.fromarray(grayscale_array)\n",
    "\n",
    "# Display the grayscale image\n",
    "grayscale_image.show(title=\"Grayscale Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=color=red>Blending Image<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9144576\n",
      "9144576\n",
      "[[ 45.    7.    9.  ...  49.5  14.5  15.5]\n",
      " [ 49.   13.5  15.5 ...  59.5   2.5  19.5]\n",
      " [ 63.5   4.   24.  ...  28.5   1.    3.5]\n",
      " ...\n",
      " [266.6 208.1 234.6 ... 151.   89.   94.5]\n",
      " [151.   89.   94.5 ...  72.    9.   14.5]\n",
      " [ 70.    7.   12.5 ... 212.3 172.3 178.8]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image as im\n",
    "i=im.open(r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg')\n",
    "# i.show()\n",
    "i2=im.open(r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg')\n",
    "# i2.show()\n",
    "i=np.resize(i,(2268,4032))\n",
    "i2=np.resize(i2,(2268,4032))\n",
    "print(i.size)\n",
    "print(i2.size)\n",
    "img=np.array(i)\n",
    "img2=np.array(i2)\n",
    "blended_img=0.5*img+0.8*img2\n",
    "print(blended_img)\n",
    "blended_img=im.fromarray(blended_img)\n",
    "blended_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGBA size=2237x2153 at 0x18799E9C870>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "base_image_path = (r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg' )\n",
    "watermark_image_path = (r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg')\n",
    "\n",
    "watermark_opacity = 0.5  \n",
    "\n",
    "base_img = Image.open(base_image_path).convert('RGB')\n",
    "watermark_img = Image.open(watermark_image_path).convert('RGBA')\n",
    "\n",
    "x = 0\n",
    "y = 0\n",
    "\n",
    "blended_img = Image.new('RGB', base_img.size) \n",
    "\n",
    "blended_img.paste(base_img, (0, 0)) \n",
    "\n",
    "blended_img.paste(watermark_img, (x, y), mask=watermark_img.split()[3]) \n",
    "\n",
    "blended_img.save('watermarked_image.jpg')\n",
    "print(watermark_img)\n",
    "watermark_img.show()\n",
    "blended_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Art<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "base_image_path = r'c:\\Users\\AZRA QADIR\\Desktop\\—Pngtree—red long-haired santa hat_5671492.png' \n",
    "texture_image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg' \n",
    "texture_scale = 0.5 \n",
    "texture_blend_ratio = 0.3\n",
    "\n",
    "base_img = Image.open(base_image_path).convert('RGB')\n",
    "texture_img = Image.open(texture_image_path).convert('RGB')\n",
    "\n",
    "texture_img = texture_img.resize((int(base_img.width * texture_scale), \n",
    "                                     int(base_img.height * texture_scale)))\n",
    "\n",
    "if base_img.size != texture_img.size:\n",
    "  base_img = base_img.resize(texture_img.size)\n",
    "\n",
    "base_img_array = np.array(base_img)\n",
    "texture_img_array = np.array(texture_img)\n",
    "\n",
    "blended_array = (texture_blend_ratio * texture_img_array) + \\\n",
    "                   ((1 - texture_blend_ratio) * base_img_array)\n",
    "blended_array = np.clip(blended_array, 0, 255).astype(np.uint8)\n",
    "\n",
    "stylized_image = Image.fromarray(blended_array)\n",
    "stylized_image.save('stylized_landscape.jpg')   \n",
    "stylized_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Augumentation<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "image1_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg' \n",
    "image2_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg'\n",
    "num_blends = 10\n",
    "\n",
    "img1 = Image.open(image1_path).convert('RGB')\n",
    "img2 = Image.open(image2_path).convert('RGB')\n",
    "\n",
    "img1 = img1.resize(img2.size) \n",
    "img2 = img2.resize(img1.size) \n",
    "\n",
    "img1_array = np.array(img1)\n",
    "img2_array = np.array(img2)\n",
    "\n",
    "for i in range(num_blends):\n",
    "  alpha = random.random()\n",
    "  blended_array = alpha * img1_array + (1 - alpha) * img2_array\n",
    "  blended_array = np.clip(blended_array, 0, 255).astype(np.uint8)\n",
    "  blended_image = Image.fromarray(blended_array)\n",
    "  blended_image.save(f\"blended_image_{i+1}.jpg\")\n",
    "  blended_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Brightness</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg' \n",
    "brightness_value = 30  \n",
    "\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "img_array = np.array(img)\n",
    "\n",
    "adjusted_array = img_array + brightness_value\n",
    "adjusted_array = np.clip(adjusted_array, 0, 255).astype(np.uint8)\n",
    "\n",
    "adjusted_img = Image.fromarray(adjusted_array)\n",
    "adjusted_img.save('brighter_image.jpg') \n",
    "adjusted_img.show()\n",
    "\n",
    "img = Image.open(image_path).convert('RGB')\n",
    "img_array = np.array(img)\n",
    "\n",
    "adjusted_array = img_array - 50 \n",
    "adjusted_array = np.clip(adjusted_array, 0, 255).astype(np.uint8)\n",
    "\n",
    "adjusted_img = Image.fromarray(adjusted_array)\n",
    "adjusted_img.save('darker_image.jpg')\n",
    "adjusted_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Overlying a small image<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# File paths (ensure these are correct)\n",
    "base_image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg'\n",
    "overlay_image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\—Pngtree—red long-haired santa hat_5671492.png'\n",
    "\n",
    "# Offset for the overlay position\n",
    "x_offset = 50\n",
    "y_offset = 50\n",
    "\n",
    "# Open base image and overlay image\n",
    "try:\n",
    "    base_img = Image.open(base_image_path).convert('RGBA')\n",
    "    overlay_img = Image.open(overlay_image_path).convert('RGBA')\n",
    "except Exception as e:\n",
    "    print(f\"Error opening images: {e}\")\n",
    "    exit()\n",
    "\n",
    "# Resize overlay image if it's larger than the base image\n",
    "if overlay_img.size[0] > base_img.size[0] or overlay_img.size[1] > base_img.size[1]:\n",
    "    overlay_img = overlay_img.resize(base_img.size, Image.Resampling.LANCZOS)\n",
    "\n",
    "# Convert images to numpy arrays\n",
    "base_img_array = np.array(base_img)\n",
    "overlay_img_array = np.array(overlay_img)\n",
    "\n",
    "# Calculate overlay region\n",
    "x1 = max(x_offset, 0)\n",
    "y1 = max(y_offset, 0)\n",
    "x2 = min(x_offset + overlay_img.size[0], base_img.size[0])\n",
    "y2 = min(y_offset + overlay_img.size[1], base_img.size[1])\n",
    "\n",
    "# Crop the overlay to fit within the base image dimensions\n",
    "overlay_cropped = overlay_img_array[:y2-y1, :x2-x1, :]\n",
    "\n",
    "# Extract alpha mask from the overlay\n",
    "overlay_mask = overlay_cropped[:, :, 3] / 255.0  # Normalize alpha channel to range [0, 1]\n",
    "overlay_mask = np.expand_dims(overlay_mask, axis=2)  # Add an extra dimension for broadcasting\n",
    "\n",
    "# Blend the overlay with the base image using the alpha mask\n",
    "base_img_array[y1:y2, x1:x2, :3] = (1 - overlay_mask) * base_img_array[y1:y2, x1:x2, :3] + \\\n",
    "                                   (overlay_mask * overlay_cropped[:, :, :3])\n",
    "\n",
    "# Convert blended array back to image\n",
    "combined_img = Image.fromarray(base_img_array.astype(np.uint8), 'RGBA')\n",
    "\n",
    "# Save and show combined image\n",
    "combined_img.save('combined_image.png')  # Save as PNG to preserve transparency\n",
    "combined_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Tiling<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-beevee-1020478.jpg' \n",
    "image = Image.open(image_path)\n",
    "\n",
    "\n",
    "width, height = image.size\n",
    "\n",
    "\n",
    "half_width = width // 2\n",
    "half_height = height // 2\n",
    "\n",
    "\n",
    "part1 = image.crop((0, 0, half_width, half_height))  # Top-left\n",
    "part2 = image.crop((half_width, 0, width, half_height))  # Top-right\n",
    "part3 = image.crop((0, half_height, half_width, height))  # Bottom-left\n",
    "part4 = image.crop((half_width, half_height, width, height))  # Bottom-right\n",
    "\n",
    "# Save each part as a separate file\n",
    "part1.save(\"part1.jpg\")\n",
    "part2.save(\"part2.jpg\")\n",
    "part3.save(\"part3.jpg\")\n",
    "part4.save(\"part4.jpg\")\n",
    "\n",
    "# Rearrange the tiles in a different order (e.g., swap top-left with bottom-right, etc.)\n",
    "new_order = [part4, part2, part3, part1]\n",
    "\n",
    "# Create a new blank image for stitching\n",
    "stitched_image = Image.new(\"RGB\", (width, height))\n",
    "\n",
    "# Paste the parts in the new order\n",
    "stitched_image.paste(new_order[0], (0, 0))  # Top-left\n",
    "stitched_image.paste(new_order[1], (half_width, 0))  # Top-right\n",
    "stitched_image.paste(new_order[2], (0, half_height))  # Bottom-left\n",
    "stitched_image.paste(new_order[3], (half_width, half_height))  # Botom-right\n",
    "\n",
    "# Save and show the stitched image\n",
    "stitched_image.save(\"stitched_image.jpg\")\n",
    "stitched_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Noise Addition<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg'  \n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Convert image to numpy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Add random noise to the image array\n",
    "noise = np.random.randint(0, 50, image_array.shape, dtype='uint8')\n",
    "noisy_image_array = image_array + noise\n",
    "\n",
    "# Clip the values to ensure they remain valid (0-255)\n",
    "noisy_image_array = np.clip(noisy_image_array, 0, 255)\n",
    "\n",
    "# Convert back to an image\n",
    "noisy_image = Image.fromarray(noisy_image_array.astype('uint8'))\n",
    "\n",
    "# Save the noisy image\n",
    "noisy_image.save(\"noisy_image.jpg\")\n",
    "noisy_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Flipping <h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "image_path = r'C:\\Users\\AZRA QADIR\\Desktop\\pexels-pixabay-47367.jpg'  # Replace with your image file\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "\n",
    "# Perform horizontal flip\n",
    "horizontally_flipped_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "horizontally_flipped_image.save(\"horizontally_flipped_image.jpg\")\n",
    "horizontally_flipped_image.show()\n",
    "\n",
    "# Perform vertical flip\n",
    "vertically_flipped_image = image.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "vertically_flipped_image.save(\"vertically_flipped_image.jpg\")\n",
    "vertically_flipped_image.show()\n",
    "\n",
    "# Perform rotation (90 degrees clockwise)\n",
    "rotated_image_90 = image.rotate(-90, expand=True)\n",
    "rotated_image_90.save(\"rotated_image_90.jpg\")\n",
    "rotated_image_90.show()\n",
    "\n",
    "# Perform rotation (180 degrees)\n",
    "rotated_image_180 = image.rotate(180, expand=True)\n",
    "rotated_image_180.save(\"rotated_image_180.jpg\")\n",
    "rotated_image_180.show()\n",
    "\n",
    "# Perform rotation (270 degrees clockwise)\n",
    "rotated_image_270 = image.rotate(-270, expand=True)\n",
    "rotated_image_270.save(\"rotated_image_270.jpg\")\n",
    "rotated_image_270.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
